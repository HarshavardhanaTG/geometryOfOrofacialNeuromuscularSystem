{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Orofacial gestures related to articulations are naturally distinguishable on the manifold of SPD matrices.\n",
    "\n",
    "Subjects perform 13 distinct orofacial gestures that play crucial role in articulation.\n",
    "They are - \n",
    "0: Cheeks - puff out, \n",
    "1: cheeks - suck in, \n",
    "2: jaw - dropdown,\n",
    "3: jaw - move backward, \n",
    "4: jaw - move forward\n",
    "5: jaw - move left, \n",
    "6: jaw - move right, \n",
    "7: lips - pucker,\n",
    "8: lips - smile, \n",
    "9: lips - tuck as if blotting,\n",
    "10: tongue - back of lower teeth,\n",
    "11: tongue - back of upper teeth\n",
    "12: tongue - the roof of the mouth\n",
    "\n",
    "DATA is given in a numpy array of dimensions (130, 22, 7500) - (13 gestures each repeated 10 times, 22 channels, 7500 time samples).\n",
    "Raw data was filtered using 3rd order Butterworth bandpass filter between 80 and 1000 Hertz. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from basicOperations.manifoldOperations import unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"Subject1\", \"Subject2\", \"Subject3\", \"Subject4\", \"Subject5\", \"Subject6\", \"Subject7\", \"Subject8\", \"Subject9\", \"Subject10\", \"Subject11\", \"Subject12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOrofacialGestures = 13\n",
    "trialsPerGesture = 10\n",
    "numberTrials = numberOrofacialGestures * trialsPerGesture\n",
    "numberChannels = 22\n",
    "windowLength = 7500\n",
    "\n",
    "LABELS = np.array([[i] * trialsPerGesture for i in range(numberOrofacialGestures)]).reshape(numberOrofacialGestures * trialsPerGesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSubjectAccuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMedoids = unsupervised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "Mean acuracy is:  0.8769230769230769\n",
      " \n",
      "Subject2\n",
      "Mean acuracy is:  0.8615384615384616\n",
      " \n",
      "Subject3\n",
      "Mean acuracy is:  0.676923076923077\n",
      " \n",
      "Subject4\n",
      "Mean acuracy is:  0.6384615384615384\n",
      " \n",
      "Subject5\n",
      "Mean acuracy is:  0.6538461538461539\n",
      " \n",
      "Subject6\n",
      "Mean acuracy is:  0.9153846153846154\n",
      " \n",
      "Subject7\n",
      "Mean acuracy is:  0.5538461538461539\n",
      " \n",
      "Subject8\n",
      "Mean acuracy is:  0.5153846153846153\n",
      " \n",
      "Subject9\n",
      "Mean acuracy is:  0.8461538461538461\n",
      " \n",
      "Subject10\n",
      "Mean acuracy is:  0.8538461538461538\n",
      " \n",
      "Subject11\n",
      "Mean acuracy is:  0.7307692307692307\n",
      " \n",
      "Subject12\n",
      "Mean acuracy is:  0.7153846153846154\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/orofacialMovements/\" + subject + \".npy\")\n",
    "\n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    DATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "    \n",
    "    covarianceMatrices = np.zeros((numberTrials, numberChannels, numberChannels))\n",
    "\n",
    "    for trial in range(numberTrials):\n",
    "       covarianceMatrices[trial] = 1/windowLength * (DATA[trial, :, :] @ np.transpose(DATA[trial, :, :]))\n",
    "\n",
    "    kmedoids = kMedoids.kMedoids(covarianceMatrices, numberChannels, numberOrofacialGestures)\n",
    "    clusterLabels = kmedoids.labels_\n",
    "    medoidIndices = kmedoids.medoid_indices_\n",
    "    medoidLabels = LABELS[medoidIndices]\n",
    "\n",
    "    assignedLabels = np.zeros((numberTrials))\n",
    "    for i in range(numberTrials):\n",
    "        assignedLabels[i] = medoidLabels[clusterLabels[i]]\n",
    "\n",
    "    allSubjectAccuracy.append(np.mean(assignedLabels == LABELS))\n",
    "\n",
    "    print(\"Mean acuracy is: \", np.mean(assignedLabels == LABELS))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7365384615384613\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allSubjectAccuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emgSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
