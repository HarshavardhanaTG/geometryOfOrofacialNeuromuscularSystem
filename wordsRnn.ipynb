{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subjects articulate 36 distinct words that span the entire English language phonetic space in `silent' and `audible' manner. \n",
    "\n",
    "\n",
    "They are - \n",
    "0. Eager \n",
    "1. lift\n",
    "2. eight\n",
    "3. edge\n",
    "4. cap\n",
    "5. matted\n",
    "6. tub\n",
    "7. box\n",
    "8. rune\n",
    "9. rook\n",
    "10. folder\n",
    "11. block\n",
    "12. fun\n",
    "13. mop\n",
    "14. pod\n",
    "15. very\n",
    "16. went\n",
    "17. throat\n",
    "18. this\n",
    "19. tango\n",
    "20. doubt\n",
    "21. not\n",
    "22. pretty\n",
    "23. xerox\n",
    "24. rodent\n",
    "25. limb\n",
    "26. batch\n",
    "27. jeep\n",
    "28. ship\n",
    "29. beige\n",
    "30. yes\n",
    "31. echo\n",
    "32. gold\n",
    "33. sing\n",
    "34. Uh-oh\n",
    "35. hiccup\n",
    "\n",
    "DATA is given in a numpy array of dimensions (360, 22, 7500) - (36 words each repeated 10 times, 22 channels, 7500 time samples).\n",
    "Raw data was filtered using 3rd order Butterworth bandpass filter between 80 and 1000 Hertz. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifoldRnn import spdNN\n",
    "from manifoldRnn import optimizers \n",
    "from manifoldRnn import trainTest\n",
    "from manifoldRnn import spdRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index].astype('float32'), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda:0\" \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberWords = 36\n",
    "trialsPerWord = 10\n",
    "numberTrials = numberWords * trialsPerWord\n",
    "numberChannels = 22\n",
    "windowLength = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectNumber = 1\n",
    "articulationManner = \"Voiced\"\n",
    "subject = \"Subject\" + str(subjectNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.load(\"Experiment1/Words/\" + articulationManner + subject + \".npy\")\n",
    "   \n",
    "mean = np.mean(DATA, axis = -1)\n",
    "std = np.std(DATA, axis = -1)\n",
    "DATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "wordMatrices = DATA\n",
    "labelsByWords = np.array([[i] * trialsPerWord for i in range(numberWords)]).reshape(numberTrials)\n",
    "\n",
    "Indices =  {}\n",
    "for i in range(numberWords):\n",
    "    Indices[i] = []\n",
    "for i in range(len(labelsByWords)):\n",
    "    Indices[labelsByWords[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicedMatrices = np.zeros((numberWords * trialsPerWord, 46, numberChannels, numberChannels))\n",
    "for j in range(numberWords * trialsPerWord):\n",
    "    for i in range(46):\n",
    "        where = i * 150 + 300\n",
    "        start = where - 300\n",
    "        End = where + 450\n",
    "        slicedMatrices[j, i] = 1/750 * wordMatrices[j, :, start:End] @ wordMatrices[j, :, start:End].T\n",
    "\n",
    "covariancesLabels = np.zeros((numberWords, trialsPerWord, 46, numberChannels, numberChannels))\n",
    "for i in range(numberWords):\n",
    "    for j in range(trialsPerWord):\n",
    "        covariancesLabels[i, j] = slicedMatrices[Indices[i][j]]\n",
    "\n",
    "trainFeatures = np.zeros((numberWords * 6, 46, numberChannels, numberChannels))\n",
    "trainLabels = np.zeros((numberWords * 6))\n",
    "count = 0\n",
    "for i in range(numberWords):\n",
    "    trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "    trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "    trainLabels[count:count + 6] = [i] * 6\n",
    "    count += 6\n",
    "\n",
    "testFeatures = np.zeros((numberWords * 4, 46, numberChannels, numberChannels))\n",
    "testLabels = np.zeros((numberWords * 4))\n",
    "count = 0\n",
    "for i in range(numberWords):\n",
    "    testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "    testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "    testLabels[count:count + 4] = [i] * 4\n",
    "    count += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = BaseDataset(trainFeatures, trainLabels)\n",
    "testDataset = BaseDataset(testFeatures, testLabels)\n",
    "trainDataloader = DataLoader(trainDataset, batch_size = 32, shuffle = True)\n",
    "testDataloader = DataLoader(testDataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146628\n"
     ]
    }
   ],
   "source": [
    "numberEpochs = 150\n",
    "\n",
    "model = spdRnn.spdRnnNet(numberWords).to(device)\n",
    "numParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(numParams)\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "cnnOptimizer = optimizers.StiefelOptim(model.CNN.parameters(), lr = 0.05)\n",
    "rnnOptimizer = optim.Adam(model.RNN.parameters(), lr = 0.001, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/150, Training loss: 0.1179, Training accuracy: 1.39%, Test loss: 0.1241, Test accuracy: 3.47%\n",
      "Epoch: 2/150, Training loss: 0.1161, Training accuracy: 0.00%, Test loss: 0.1233, Test accuracy: 3.47%\n",
      "Epoch: 3/150, Training loss: 0.1153, Training accuracy: 5.09%, Test loss: 0.1227, Test accuracy: 14.58%\n",
      "Epoch: 4/150, Training loss: 0.1143, Training accuracy: 7.87%, Test loss: 0.1218, Test accuracy: 6.25%\n",
      "Epoch: 5/150, Training loss: 0.1130, Training accuracy: 12.04%, Test loss: 0.1182, Test accuracy: 15.28%\n",
      "Epoch: 6/150, Training loss: 0.1101, Training accuracy: 10.19%, Test loss: 0.1149, Test accuracy: 14.58%\n",
      "Epoch: 7/150, Training loss: 0.1039, Training accuracy: 11.11%, Test loss: 0.1086, Test accuracy: 10.42%\n",
      "Epoch: 8/150, Training loss: 0.1008, Training accuracy: 11.11%, Test loss: 0.1062, Test accuracy: 21.53%\n",
      "Epoch: 9/150, Training loss: 0.0943, Training accuracy: 17.13%, Test loss: 0.1058, Test accuracy: 11.81%\n",
      "Epoch: 10/150, Training loss: 0.0918, Training accuracy: 18.06%, Test loss: 0.0992, Test accuracy: 22.22%\n",
      "Epoch: 11/150, Training loss: 0.0884, Training accuracy: 19.91%, Test loss: 0.1005, Test accuracy: 15.97%\n",
      "Epoch: 12/150, Training loss: 0.0830, Training accuracy: 26.85%, Test loss: 0.0853, Test accuracy: 27.78%\n",
      "Epoch: 13/150, Training loss: 0.0743, Training accuracy: 31.94%, Test loss: 0.0868, Test accuracy: 31.25%\n",
      "Epoch: 14/150, Training loss: 0.0738, Training accuracy: 33.80%, Test loss: 0.0834, Test accuracy: 34.03%\n",
      "Epoch: 15/150, Training loss: 0.0694, Training accuracy: 38.89%, Test loss: 0.0779, Test accuracy: 38.89%\n",
      "Epoch: 16/150, Training loss: 0.0645, Training accuracy: 40.28%, Test loss: 0.0773, Test accuracy: 34.72%\n",
      "Epoch: 17/150, Training loss: 0.0672, Training accuracy: 34.72%, Test loss: 0.0853, Test accuracy: 33.33%\n",
      "Epoch: 18/150, Training loss: 0.0650, Training accuracy: 42.59%, Test loss: 0.0728, Test accuracy: 31.94%\n",
      "Epoch: 19/150, Training loss: 0.0596, Training accuracy: 39.35%, Test loss: 0.0640, Test accuracy: 38.89%\n",
      "Epoch: 20/150, Training loss: 0.0522, Training accuracy: 50.46%, Test loss: 0.0623, Test accuracy: 46.53%\n",
      "Epoch: 21/150, Training loss: 0.0473, Training accuracy: 58.80%, Test loss: 0.0642, Test accuracy: 45.83%\n",
      "Epoch: 22/150, Training loss: 0.0455, Training accuracy: 58.33%, Test loss: 0.0687, Test accuracy: 38.89%\n",
      "Epoch: 23/150, Training loss: 0.0439, Training accuracy: 59.72%, Test loss: 0.0657, Test accuracy: 45.14%\n",
      "Epoch: 24/150, Training loss: 0.0372, Training accuracy: 63.89%, Test loss: 0.0578, Test accuracy: 47.22%\n",
      "Epoch: 25/150, Training loss: 0.0334, Training accuracy: 69.91%, Test loss: 0.0564, Test accuracy: 52.08%\n",
      "Epoch: 26/150, Training loss: 0.0342, Training accuracy: 67.59%, Test loss: 0.0551, Test accuracy: 47.92%\n",
      "Epoch: 27/150, Training loss: 0.0317, Training accuracy: 72.22%, Test loss: 0.0545, Test accuracy: 52.08%\n",
      "Epoch: 28/150, Training loss: 0.0306, Training accuracy: 71.30%, Test loss: 0.0587, Test accuracy: 50.69%\n",
      "Epoch: 29/150, Training loss: 0.0283, Training accuracy: 74.07%, Test loss: 0.0612, Test accuracy: 48.61%\n",
      "Epoch: 30/150, Training loss: 0.0331, Training accuracy: 66.67%, Test loss: 0.0569, Test accuracy: 45.14%\n",
      "Epoch: 31/150, Training loss: 0.0280, Training accuracy: 71.30%, Test loss: 0.0575, Test accuracy: 52.78%\n",
      "Epoch: 32/150, Training loss: 0.0294, Training accuracy: 69.44%, Test loss: 0.0463, Test accuracy: 63.19%\n",
      "Epoch: 33/150, Training loss: 0.0243, Training accuracy: 78.70%, Test loss: 0.0591, Test accuracy: 50.00%\n",
      "Epoch: 34/150, Training loss: 0.0203, Training accuracy: 78.70%, Test loss: 0.0529, Test accuracy: 53.47%\n",
      "Epoch: 35/150, Training loss: 0.0234, Training accuracy: 79.63%, Test loss: 0.0463, Test accuracy: 56.94%\n",
      "Epoch: 36/150, Training loss: 0.0168, Training accuracy: 84.72%, Test loss: 0.0433, Test accuracy: 60.42%\n",
      "Epoch: 37/150, Training loss: 0.0197, Training accuracy: 81.48%, Test loss: 0.0456, Test accuracy: 54.17%\n",
      "Epoch: 38/150, Training loss: 0.0201, Training accuracy: 79.63%, Test loss: 0.0520, Test accuracy: 60.42%\n",
      "Epoch: 39/150, Training loss: 0.0223, Training accuracy: 74.07%, Test loss: 0.0511, Test accuracy: 52.08%\n",
      "Epoch: 40/150, Training loss: 0.0214, Training accuracy: 77.78%, Test loss: 0.0475, Test accuracy: 60.42%\n",
      "Epoch: 41/150, Training loss: 0.0162, Training accuracy: 86.57%, Test loss: 0.0377, Test accuracy: 62.50%\n",
      "Epoch: 42/150, Training loss: 0.0143, Training accuracy: 88.43%, Test loss: 0.0474, Test accuracy: 64.58%\n",
      "Epoch: 43/150, Training loss: 0.0134, Training accuracy: 90.74%, Test loss: 0.0553, Test accuracy: 58.33%\n",
      "Epoch: 44/150, Training loss: 0.0145, Training accuracy: 91.67%, Test loss: 0.0348, Test accuracy: 70.14%\n",
      "Epoch: 45/150, Training loss: 0.0127, Training accuracy: 88.89%, Test loss: 0.0342, Test accuracy: 68.75%\n",
      "Epoch: 46/150, Training loss: 0.0110, Training accuracy: 91.20%, Test loss: 0.0391, Test accuracy: 64.58%\n",
      "Epoch: 47/150, Training loss: 0.0090, Training accuracy: 92.59%, Test loss: 0.0411, Test accuracy: 70.14%\n",
      "Epoch: 48/150, Training loss: 0.0084, Training accuracy: 91.20%, Test loss: 0.0481, Test accuracy: 68.75%\n",
      "Epoch: 49/150, Training loss: 0.0099, Training accuracy: 92.59%, Test loss: 0.0348, Test accuracy: 70.14%\n",
      "Epoch: 50/150, Training loss: 0.0124, Training accuracy: 90.28%, Test loss: 0.0418, Test accuracy: 63.19%\n",
      "Epoch: 51/150, Training loss: 0.0178, Training accuracy: 86.11%, Test loss: 0.0393, Test accuracy: 65.28%\n",
      "Epoch: 52/150, Training loss: 0.0143, Training accuracy: 86.57%, Test loss: 0.0354, Test accuracy: 68.06%\n",
      "Epoch: 53/150, Training loss: 0.0119, Training accuracy: 89.81%, Test loss: 0.0366, Test accuracy: 68.75%\n",
      "Epoch: 54/150, Training loss: 0.0111, Training accuracy: 90.74%, Test loss: 0.0471, Test accuracy: 60.42%\n",
      "Epoch: 55/150, Training loss: 0.0100, Training accuracy: 90.28%, Test loss: 0.0415, Test accuracy: 70.14%\n",
      "Epoch: 56/150, Training loss: 0.0089, Training accuracy: 93.52%, Test loss: 0.0445, Test accuracy: 67.36%\n",
      "Epoch: 57/150, Training loss: 0.0057, Training accuracy: 95.37%, Test loss: 0.0348, Test accuracy: 68.06%\n",
      "Epoch: 58/150, Training loss: 0.0053, Training accuracy: 97.22%, Test loss: 0.0356, Test accuracy: 72.92%\n",
      "Epoch: 59/150, Training loss: 0.0042, Training accuracy: 98.15%, Test loss: 0.0373, Test accuracy: 70.83%\n",
      "Epoch: 60/150, Training loss: 0.0056, Training accuracy: 97.69%, Test loss: 0.0446, Test accuracy: 72.92%\n",
      "Epoch: 61/150, Training loss: 0.0114, Training accuracy: 88.43%, Test loss: 0.0470, Test accuracy: 62.50%\n",
      "Epoch: 62/150, Training loss: 0.0120, Training accuracy: 87.50%, Test loss: 0.0467, Test accuracy: 69.44%\n",
      "Epoch: 63/150, Training loss: 0.0172, Training accuracy: 82.41%, Test loss: 0.0440, Test accuracy: 65.28%\n",
      "Epoch: 64/150, Training loss: 0.0111, Training accuracy: 87.50%, Test loss: 0.0487, Test accuracy: 62.50%\n",
      "Epoch: 65/150, Training loss: 0.0092, Training accuracy: 90.28%, Test loss: 0.0334, Test accuracy: 72.22%\n",
      "Epoch: 66/150, Training loss: 0.0061, Training accuracy: 94.91%, Test loss: 0.0426, Test accuracy: 64.58%\n",
      "Epoch: 67/150, Training loss: 0.0067, Training accuracy: 94.91%, Test loss: 0.0403, Test accuracy: 66.67%\n",
      "Epoch: 68/150, Training loss: 0.0059, Training accuracy: 95.83%, Test loss: 0.0451, Test accuracy: 63.89%\n",
      "Epoch: 69/150, Training loss: 0.0042, Training accuracy: 98.15%, Test loss: 0.0298, Test accuracy: 77.08%\n",
      "Epoch: 70/150, Training loss: 0.0031, Training accuracy: 99.54%, Test loss: 0.0339, Test accuracy: 72.22%\n",
      "Epoch: 71/150, Training loss: 0.0022, Training accuracy: 99.54%, Test loss: 0.0361, Test accuracy: 74.31%\n",
      "Epoch: 72/150, Training loss: 0.0015, Training accuracy: 100.00%, Test loss: 0.0287, Test accuracy: 79.86%\n",
      "Epoch: 73/150, Training loss: 0.0015, Training accuracy: 100.00%, Test loss: 0.0308, Test accuracy: 78.47%\n",
      "Epoch: 74/150, Training loss: 0.0012, Training accuracy: 100.00%, Test loss: 0.0347, Test accuracy: 75.69%\n",
      "Epoch: 75/150, Training loss: 0.0011, Training accuracy: 100.00%, Test loss: 0.0318, Test accuracy: 76.39%\n",
      "Epoch: 76/150, Training loss: 0.0011, Training accuracy: 99.54%, Test loss: 0.0301, Test accuracy: 76.39%\n",
      "Epoch: 77/150, Training loss: 0.0010, Training accuracy: 100.00%, Test loss: 0.0318, Test accuracy: 76.39%\n",
      "Epoch: 78/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0324, Test accuracy: 77.78%\n",
      "Epoch: 79/150, Training loss: 0.0007, Training accuracy: 100.00%, Test loss: 0.0303, Test accuracy: 77.78%\n",
      "Epoch: 80/150, Training loss: 0.0007, Training accuracy: 100.00%, Test loss: 0.0312, Test accuracy: 77.08%\n",
      "Epoch: 81/150, Training loss: 0.0006, Training accuracy: 100.00%, Test loss: 0.0332, Test accuracy: 75.69%\n",
      "Epoch: 82/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0332, Test accuracy: 75.69%\n",
      "Epoch: 83/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0320, Test accuracy: 76.39%\n",
      "Epoch: 84/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0327, Test accuracy: 76.39%\n",
      "Epoch: 85/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0337, Test accuracy: 75.69%\n",
      "Epoch: 86/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0334, Test accuracy: 75.69%\n",
      "Epoch: 87/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0321, Test accuracy: 76.39%\n",
      "Epoch: 88/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0328, Test accuracy: 76.39%\n",
      "Epoch: 89/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0333, Test accuracy: 75.69%\n",
      "Epoch: 90/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0321, Test accuracy: 76.39%\n",
      "Epoch: 91/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0322, Test accuracy: 75.69%\n",
      "Epoch: 92/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0330, Test accuracy: 75.00%\n",
      "Epoch: 93/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0329, Test accuracy: 75.00%\n",
      "Epoch: 94/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0328, Test accuracy: 75.00%\n",
      "Epoch: 95/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0335, Test accuracy: 75.69%\n",
      "Epoch: 96/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0337, Test accuracy: 75.00%\n",
      "Epoch: 97/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0336, Test accuracy: 75.69%\n",
      "Epoch: 98/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0335, Test accuracy: 75.69%\n",
      "Epoch: 99/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0338, Test accuracy: 75.00%\n",
      "Epoch: 100/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0342, Test accuracy: 74.31%\n",
      "Epoch: 101/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0343, Test accuracy: 74.31%\n",
      "Epoch: 102/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0360, Test accuracy: 75.00%\n",
      "Epoch: 103/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0361, Test accuracy: 73.61%\n",
      "Epoch: 104/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0351, Test accuracy: 75.69%\n",
      "Epoch: 105/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0347, Test accuracy: 77.08%\n",
      "Epoch: 106/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0344, Test accuracy: 76.39%\n",
      "Epoch: 107/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0357, Test accuracy: 74.31%\n",
      "Epoch: 108/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0355, Test accuracy: 74.31%\n",
      "Epoch: 109/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0345, Test accuracy: 74.31%\n",
      "Epoch: 110/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0350, Test accuracy: 74.31%\n",
      "Epoch: 111/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0352, Test accuracy: 75.00%\n",
      "Epoch: 112/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0349, Test accuracy: 75.00%\n",
      "Epoch: 113/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0351, Test accuracy: 75.00%\n",
      "Epoch: 114/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0346, Test accuracy: 74.31%\n",
      "Epoch: 115/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0346, Test accuracy: 75.00%\n",
      "Epoch: 116/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0350, Test accuracy: 74.31%\n",
      "Epoch: 117/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0351, Test accuracy: 75.00%\n",
      "Epoch: 118/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0352, Test accuracy: 75.00%\n",
      "Epoch: 119/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0359, Test accuracy: 75.00%\n",
      "Epoch: 120/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0365, Test accuracy: 74.31%\n",
      "Epoch: 121/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0365, Test accuracy: 74.31%\n",
      "Epoch: 122/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0363, Test accuracy: 74.31%\n",
      "Epoch: 123/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0356, Test accuracy: 74.31%\n",
      "Epoch: 124/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0355, Test accuracy: 75.00%\n",
      "Epoch: 125/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0359, Test accuracy: 75.00%\n",
      "Epoch: 126/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0364, Test accuracy: 72.92%\n",
      "Epoch: 127/150, Training loss: 0.0002, Training accuracy: 100.00%, Test loss: 0.0361, Test accuracy: 74.31%\n",
      "Epoch: 128/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0367, Test accuracy: 73.61%\n",
      "Epoch: 129/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0364, Test accuracy: 73.61%\n",
      "Epoch: 130/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0357, Test accuracy: 75.00%\n",
      "Epoch: 131/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0363, Test accuracy: 75.00%\n",
      "Epoch: 132/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0362, Test accuracy: 75.69%\n",
      "Epoch: 133/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0357, Test accuracy: 75.69%\n",
      "Epoch: 134/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0361, Test accuracy: 75.69%\n",
      "Epoch: 135/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0365, Test accuracy: 74.31%\n",
      "Epoch: 136/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0370, Test accuracy: 73.61%\n",
      "Epoch: 137/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0378, Test accuracy: 74.31%\n",
      "Epoch: 138/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0391, Test accuracy: 74.31%\n",
      "Epoch: 139/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0386, Test accuracy: 75.00%\n",
      "Epoch: 140/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0371, Test accuracy: 74.31%\n",
      "Epoch: 141/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0371, Test accuracy: 74.31%\n",
      "Epoch: 142/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0365, Test accuracy: 75.69%\n",
      "Epoch: 143/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0370, Test accuracy: 72.92%\n",
      "Epoch: 144/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0362, Test accuracy: 73.61%\n",
      "Epoch: 145/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0363, Test accuracy: 74.31%\n",
      "Epoch: 146/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0369, Test accuracy: 73.61%\n",
      "Epoch: 147/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0380, Test accuracy: 74.31%\n",
      "Epoch: 148/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0380, Test accuracy: 73.61%\n",
      "Epoch: 149/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0375, Test accuracy: 74.31%\n",
      "Epoch: 150/150, Training loss: 0.0001, Training accuracy: 100.00%, Test loss: 0.0375, Test accuracy: 74.31%\n",
      "79.86111111111111\n"
     ]
    }
   ],
   "source": [
    "maxValue = 0\n",
    "for epoch in range(numberEpochs):\n",
    "    trainLoss, trainAccuracy = trainTest.trainOperation(model, device, trainDataloader, cnnOptimizer, rnnOptimizer, lossFunction)\n",
    "    testLoss, testAccuracy = trainTest.testOperation(model, device, testDataloader, lossFunction)\n",
    "    if maxValue < testAccuracy:\n",
    "        maxValue = testAccuracy\n",
    "    print(f'Epoch: {epoch + 1}/{numberEpochs}, Training loss: {trainLoss:.4f}, Training accuracy: {trainAccuracy:.2f}%, Test loss: {testLoss:.4f}, Test accuracy: {testAccuracy:.2f}%')\n",
    "print(maxValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.86111111111111\n"
     ]
    }
   ],
   "source": [
    "print(maxValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emgSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
