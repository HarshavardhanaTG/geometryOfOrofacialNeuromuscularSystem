{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Phoneme articulations are naturally distinguishable on the manifold of SPD matrices.\n",
    "\n",
    "Subjects articulate 38 distinct phonemes that span the entire English language phonetic space in `silent' and `audible' manner. \n",
    "\n",
    "38 phonemes are (labels are given in brackets beside the phoneme)\n",
    "\n",
    "Bilabial consonants: Baa (0), Paa (1), Maa (2)\n",
    "Labiodental consonants: Faa (3), Vaa (4)\n",
    "Dental consonants: Thaa (5), Dhaa (6)\n",
    "Alvelor consonants: Taa (7), Daa (8), Naa (9), Saa (10), Zaa (11)\n",
    "Post vaelor consonants: Chaa (12), Shaa (13), Jhaa (14), Zhaa (15)\n",
    "Velar consonants: Kaa (!6), Gaa (17), NGaa (18)\n",
    "Approximant consonants: Yaa (19), Raa (20), Laa (21), Waa (22)\n",
    "Vowels:\n",
    "OY as in bOY (23), OW as in nOW (24),\n",
    "AO as in OUght (25), AA as in fAther (26),\n",
    "AE as in At (27), EH as in mEt (28),\n",
    "EY as in mAte (29), IY as in mEET (30),\n",
    "IH as in It (31), AH as in HUt (32),\n",
    "UW as in fOOD (33), ER as in hER (34),\n",
    "UH as in hOOD (35)\n",
    "\n",
    "DATA is given in a numpy array of dimensions (380, 22, 7500) - (38 phonemes each repeated 10 times, 22 channels, 7500 time samples).\n",
    "Raw data was filtered using 3rd order Butterworth bandpass filter between 80 and 1000 Hertz.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from basicOperations.manifoldOperations import matrixDistance, frechetMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"Subject1\", \"Subject2\", \"Subject3\", \"Subject4\", \"Subject5\", \"Subject6\", \"Subject7\", \"Subject8\", \"Subject9\", \"Subject10\", \"Subject12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberPhonemes = 38\n",
    "numberConsonantPhoneme = 23\n",
    "numberVowelPhoneme = 15\n",
    "\n",
    "trialsPerPhoneme = 10\n",
    "numberTrials = numberPhonemes * trialsPerPhoneme\n",
    "numberChannels = 22\n",
    "windowLength = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesicDistance = matrixDistance()\n",
    "manifoldMean = frechetMean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "0.375\n",
      " \n",
      "Subject2\n",
      "0.5131578947368421\n",
      " \n",
      "Subject3\n",
      "0.2631578947368421\n",
      " \n",
      "Subject4\n",
      "0.19736842105263158\n",
      " \n",
      "Subject5\n",
      "0.47368421052631576\n",
      " \n",
      "Subject6\n",
      "0.5\n",
      " \n",
      "Subject7\n",
      "0.19078947368421054\n",
      " \n",
      "Subject8\n",
      "0.32894736842105265\n",
      " \n",
      "Subject9\n",
      "0.35526315789473684\n",
      " \n",
      "Subject10\n",
      "0.4144736842105263\n",
      " \n",
      "Subject12\n",
      "0.34868421052631576\n",
      " \n"
     ]
    }
   ],
   "source": [
    "allAccuracyVoiced = []\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/Phoneme/Voiced\" + subject + \".npy\")\n",
    "   \n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    voicedDATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "    phonemeMatrices = voicedDATA\n",
    "    labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberPhonemes)]).reshape(numberTrials)\n",
    "\n",
    "    Indices =  {}\n",
    "    for i in range(numberPhonemes):\n",
    "        Indices[i] = []\n",
    "    for i in range(len(labelsByPhonemes)):\n",
    "        Indices[labelsByPhonemes[i]].append(i)\n",
    "\n",
    "    covariancesLabels = np.zeros((numberPhonemes, trialsPerPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberPhonemes):\n",
    "        for j in range(trialsPerPhoneme):\n",
    "            covariancesLabels[i, j] = 1/windowLength * (phonemeMatrices[Indices[i][j]] @ phonemeMatrices[Indices[i][j]].T)\n",
    "\n",
    "    trainFeatures = np.zeros((numberPhonemes * 6, numberChannels, numberChannels))\n",
    "    trainLabels = np.zeros((numberPhonemes * 6))\n",
    "    count = 0\n",
    "    for i in range(numberPhonemes):\n",
    "        trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "        trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "        trainLabels[count:count + 6] = [i] * 6\n",
    "        count += 6\n",
    "\n",
    "    testFeatures = np.zeros((numberPhonemes * 4, numberChannels, numberChannels))\n",
    "    testLabels = np.zeros((numberPhonemes * 4))\n",
    "    count = 0\n",
    "    for i in range(numberPhonemes):\n",
    "        testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "        testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "        testLabels[count:count + 4] = [i] * 4\n",
    "        count += 4\n",
    "\n",
    "    trainCentroid = np.zeros((numberPhonemes, numberChannels, numberChannels))\n",
    "    for i in range(numberPhonemes):\n",
    "        trainCentroid[i, :, :] = manifoldMean.mean(trainFeatures[i * 6: i * 6 + 6])\n",
    "\n",
    "    predictLabels = np.zeros((4 * numberPhonemes))\n",
    "    for k in range(4 * numberPhonemes):\n",
    "        distances = np.zeros((numberPhonemes))\n",
    "        for m in range(numberPhonemes):\n",
    "            distances[m] = geodesicDistance.distance(testFeatures[k], trainCentroid[m])\n",
    "        predictLabels[k] = np.argmin(distances)\n",
    "\n",
    "    correct = (predictLabels == testLabels)\n",
    "    print(np.mean(correct))\n",
    "    print(\" \")\n",
    "    allAccuracyVoiced.append(np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3600478468899521\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allAccuracyVoiced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "0.5\n",
      " \n",
      "Subject2\n",
      "0.4934210526315789\n",
      " \n",
      "Subject3\n",
      "0.28289473684210525\n",
      " \n",
      "Subject4\n",
      "0.32894736842105265\n",
      " \n",
      "Subject5\n",
      "0.4473684210526316\n",
      " \n",
      "Subject6\n",
      "0.45394736842105265\n",
      " \n",
      "Subject7\n",
      "0.26973684210526316\n",
      " \n",
      "Subject8\n",
      "0.3026315789473684\n",
      " \n",
      "Subject9\n",
      "0.23026315789473684\n",
      " \n",
      "Subject10\n",
      "0.3092105263157895\n",
      " \n",
      "Subject12\n",
      "0.3157894736842105\n",
      " \n"
     ]
    }
   ],
   "source": [
    "allAccuracyUnvoiced = []\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/Phoneme/Unvoiced\" + subject + \".npy\")\n",
    "   \n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    unvoicedDATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "    phonemeMatrices = unvoicedDATA\n",
    "    labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberPhonemes)]).reshape(numberTrials)\n",
    "\n",
    "    Indices =  {}\n",
    "    for i in range(numberPhonemes):\n",
    "        Indices[i] = []\n",
    "    for i in range(len(labelsByPhonemes)):\n",
    "        Indices[labelsByPhonemes[i]].append(i)\n",
    "\n",
    "    covariancesLabels = np.zeros((numberPhonemes, trialsPerPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberPhonemes):\n",
    "        for j in range(trialsPerPhoneme):\n",
    "            covariancesLabels[i, j] = 1/windowLength * (phonemeMatrices[Indices[i][j]] @ phonemeMatrices[Indices[i][j]].T)\n",
    "\n",
    "    trainFeatures = np.zeros((numberPhonemes * 6, numberChannels, numberChannels))\n",
    "    trainLabels = np.zeros((numberPhonemes * 6))\n",
    "    count = 0\n",
    "    for i in range(numberPhonemes):\n",
    "        trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "        trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "        trainLabels[count:count + 6] = [i] * 6\n",
    "        count += 6\n",
    "\n",
    "    testFeatures = np.zeros((numberPhonemes * 4, numberChannels, numberChannels))\n",
    "    testLabels = np.zeros((numberPhonemes * 4))\n",
    "    count = 0\n",
    "    for i in range(numberPhonemes):\n",
    "        testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "        testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "        testLabels[count:count + 4] = [i] * 4\n",
    "        count += 4\n",
    "\n",
    "    trainCentroid = np.zeros((numberPhonemes, numberChannels, numberChannels))\n",
    "    for i in range(numberPhonemes):\n",
    "        trainCentroid[i, :, :] = manifoldMean.mean(trainFeatures[i * 6: i * 6 + 6])\n",
    "\n",
    "    predictLabels = np.zeros((4 * numberPhonemes))\n",
    "    for k in range(4 * numberPhonemes):\n",
    "        distances = np.zeros((numberPhonemes))\n",
    "        for m in range(numberPhonemes):\n",
    "            distances[m] = geodesicDistance.distance(testFeatures[k], trainCentroid[m])\n",
    "        predictLabels[k] = np.argmin(distances)\n",
    "\n",
    "    correct = (predictLabels == testLabels)\n",
    "    print(np.mean(correct))\n",
    "    print(\" \")\n",
    "    allAccuracyUnvoiced.append(np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3576555023923445\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allAccuracyUnvoiced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "0.33695652173913043\n",
      " \n",
      "Subject2\n",
      "0.4673913043478261\n",
      " \n",
      "Subject3\n",
      "0.18478260869565216\n",
      " \n",
      "Subject4\n",
      "0.22826086956521738\n",
      " \n",
      "Subject5\n",
      "0.5217391304347826\n",
      " \n",
      "Subject6\n",
      "0.45652173913043476\n",
      " \n",
      "Subject7\n",
      "0.25\n",
      " \n",
      "Subject8\n",
      "0.45652173913043476\n",
      " \n",
      "Subject9\n",
      "0.2608695652173913\n",
      " \n",
      "Subject10\n",
      "0.41304347826086957\n",
      " \n",
      "Subject12\n",
      "0.41304347826086957\n",
      " \n"
     ]
    }
   ],
   "source": [
    "allConsonantAccuracyVoiced = []\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/Phoneme/Voiced\" + subject + \".npy\")\n",
    "   \n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    voicedDATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "    phonemeMatrices = voicedDATA\n",
    "    labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberConsonantPhoneme)]).reshape(numberConsonantPhoneme * trialsPerPhoneme)\n",
    "\n",
    "    Indices =  {}\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        Indices[i] = []\n",
    "    for i in range(len(labelsByPhonemes)):\n",
    "        Indices[labelsByPhonemes[i]].append(i)\n",
    "\n",
    "    covariancesLabels = np.zeros((numberConsonantPhoneme, trialsPerPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        for j in range(trialsPerPhoneme):\n",
    "            covariancesLabels[i, j] = 1/windowLength * (phonemeMatrices[Indices[i][j]] @ phonemeMatrices[Indices[i][j]].T)\n",
    "\n",
    "    trainFeatures = np.zeros((numberConsonantPhoneme * 6, numberChannels, numberChannels))\n",
    "    trainLabels = np.zeros((numberConsonantPhoneme * 6))\n",
    "    count = 0\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "        trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "        trainLabels[count:count + 6] = [i] * 6\n",
    "        count += 6\n",
    "\n",
    "    testFeatures = np.zeros((numberConsonantPhoneme * 4, numberChannels, numberChannels))\n",
    "    testLabels = np.zeros((numberConsonantPhoneme * 4))\n",
    "    count = 0\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "        testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "        testLabels[count:count + 4] = [i] * 4\n",
    "        count += 4\n",
    "\n",
    "    trainCentroid = np.zeros((numberConsonantPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        trainCentroid[i, :, :] = manifoldMean.mean(trainFeatures[i * 6: i * 6 + 6])\n",
    "\n",
    "    predictLabels = np.zeros((4 * numberConsonantPhoneme))\n",
    "    for k in range(4 * numberConsonantPhoneme):\n",
    "        distances = np.zeros((numberConsonantPhoneme))\n",
    "        for m in range(numberConsonantPhoneme):\n",
    "            distances[m] = geodesicDistance.distance(testFeatures[k], trainCentroid[m])\n",
    "        predictLabels[k] = np.argmin(distances)\n",
    "\n",
    "    correct = (predictLabels == testLabels)\n",
    "    print(np.mean(correct))\n",
    "    print(\" \")\n",
    "    allConsonantAccuracyVoiced.append(np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36264822134387353\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allConsonantAccuracyVoiced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "0.4673913043478261\n",
      " \n",
      "Subject2\n",
      "0.42391304347826086\n",
      " \n",
      "Subject3\n",
      "0.29347826086956524\n",
      " \n",
      "Subject4\n",
      "0.3804347826086957\n",
      " \n",
      "Subject5\n",
      "0.41304347826086957\n",
      " \n",
      "Subject6\n",
      "0.41304347826086957\n",
      " \n",
      "Subject7\n",
      "0.2826086956521739\n",
      " \n",
      "Subject8\n",
      "0.32608695652173914\n",
      " \n",
      "Subject9\n",
      "0.17391304347826086\n",
      " \n",
      "Subject10\n",
      "0.22826086956521738\n",
      " \n",
      "Subject12\n",
      "0.391304347826087\n",
      " \n"
     ]
    }
   ],
   "source": [
    "allConsonantAccuracyUnvoiced = []\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/Phoneme/Unvoiced\" + subject + \".npy\")\n",
    "   \n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    unvoicedDATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "    phonemeMatrices = unvoicedDATA\n",
    "    labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberConsonantPhoneme)]).reshape(numberConsonantPhoneme * trialsPerPhoneme)\n",
    "\n",
    "    Indices =  {}\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        Indices[i] = []\n",
    "    for i in range(len(labelsByPhonemes)):\n",
    "        Indices[labelsByPhonemes[i]].append(i)\n",
    "\n",
    "    covariancesLabels = np.zeros((numberConsonantPhoneme, trialsPerPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        for j in range(trialsPerPhoneme):\n",
    "            covariancesLabels[i, j] = 1/windowLength * (phonemeMatrices[Indices[i][j]] @ phonemeMatrices[Indices[i][j]].T)\n",
    "\n",
    "    trainFeatures = np.zeros((numberConsonantPhoneme * 6, numberChannels, numberChannels))\n",
    "    trainLabels = np.zeros((numberConsonantPhoneme * 6))\n",
    "    count = 0\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "        trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "        trainLabels[count:count + 6] = [i] * 6\n",
    "        count += 6\n",
    "\n",
    "    testFeatures = np.zeros((numberConsonantPhoneme * 4, numberChannels, numberChannels))\n",
    "    testLabels = np.zeros((numberConsonantPhoneme * 4))\n",
    "    count = 0\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "        testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "        testLabels[count:count + 4] = [i] * 4\n",
    "        count += 4\n",
    "\n",
    "    trainCentroid = np.zeros((numberConsonantPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberConsonantPhoneme):\n",
    "        trainCentroid[i, :, :] = manifoldMean.mean(trainFeatures[i * 6: i * 6 + 6])\n",
    "\n",
    "    predictLabels = np.zeros((4 * numberConsonantPhoneme))\n",
    "    for k in range(4 * numberConsonantPhoneme):\n",
    "        distances = np.zeros((numberConsonantPhoneme))\n",
    "        for m in range(numberConsonantPhoneme):\n",
    "            distances[m] = geodesicDistance.distance(testFeatures[k], trainCentroid[m])\n",
    "        predictLabels[k] = np.argmin(distances)\n",
    "\n",
    "    correct = (predictLabels == testLabels)\n",
    "    print(np.mean(correct))\n",
    "    print(\" \")\n",
    "    allConsonantAccuracyUnvoiced.append(np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34486166007905134\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allConsonantAccuracyUnvoiced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "0.5166666666666667\n",
      " \n",
      "Subject2\n",
      "0.6666666666666666\n",
      " \n",
      "Subject3\n",
      "0.45\n",
      " \n",
      "Subject4\n",
      "0.25\n",
      " \n",
      "Subject5\n",
      "0.5333333333333333\n",
      " \n",
      "Subject6\n",
      "0.5833333333333334\n",
      " \n",
      "Subject7\n",
      "0.2\n",
      " \n",
      "Subject8\n",
      "0.3333333333333333\n",
      " \n",
      "Subject9\n",
      "0.6\n",
      " \n",
      "Subject10\n",
      "0.48333333333333334\n",
      " \n",
      "Subject12\n",
      "0.38333333333333336\n",
      " \n"
     ]
    }
   ],
   "source": [
    "allVowelAccuracyVoiced = []\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/Phoneme/Voiced\" + subject + \".npy\")\n",
    "   \n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    voicedDATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "    phonemeMatrices = voicedDATA\n",
    "    labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberVowelPhoneme)]).reshape(numberVowelPhoneme * trialsPerPhoneme)\n",
    "\n",
    "    Indices =  {}\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        Indices[i] = []\n",
    "    for i in range(len(labelsByPhonemes)):\n",
    "        Indices[labelsByPhonemes[i]].append(i)\n",
    "\n",
    "    covariancesLabels = np.zeros((numberVowelPhoneme, trialsPerPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        for j in range(trialsPerPhoneme):\n",
    "            covariancesLabels[i, j] = 1/windowLength * (phonemeMatrices[230 + Indices[i][j]] @ phonemeMatrices[230 + Indices[i][j]].T)\n",
    "\n",
    "    trainFeatures = np.zeros((numberVowelPhoneme * 6, numberChannels, numberChannels))\n",
    "    trainLabels = np.zeros((numberVowelPhoneme * 6))\n",
    "    count = 0\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "        trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "        trainLabels[count:count + 6] = [i] * 6\n",
    "        count += 6\n",
    "\n",
    "    testFeatures = np.zeros((numberVowelPhoneme * 4, numberChannels, numberChannels))\n",
    "    testLabels = np.zeros((numberVowelPhoneme * 4))\n",
    "    count = 0\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "        testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "        testLabels[count:count + 4] = [i] * 4\n",
    "        count += 4\n",
    "\n",
    "    trainCentroid = np.zeros((numberVowelPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        trainCentroid[i, :, :] = manifoldMean.mean(trainFeatures[i * 6: i * 6 + 6])\n",
    "\n",
    "    predictLabels = np.zeros((4 * numberVowelPhoneme))\n",
    "    for k in range(4 * numberVowelPhoneme):\n",
    "        distances = np.zeros((numberVowelPhoneme))\n",
    "        for m in range(numberVowelPhoneme):\n",
    "            distances[m] = geodesicDistance.distance(testFeatures[k], trainCentroid[m])\n",
    "        predictLabels[k] = np.argmin(distances)\n",
    "\n",
    "    correct = (predictLabels == testLabels)\n",
    "    print(np.mean(correct))\n",
    "    print(\" \")\n",
    "    allVowelAccuracyVoiced.append(np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allVowelAccuracyVoiced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "0.5666666666666667\n",
      " \n",
      "Subject2\n",
      "0.6333333333333333\n",
      " \n",
      "Subject3\n",
      "0.3\n",
      " \n",
      "Subject4\n",
      "0.43333333333333335\n",
      " \n",
      "Subject5\n",
      "0.5833333333333334\n",
      " \n",
      "Subject6\n",
      "0.5833333333333334\n",
      " \n",
      "Subject7\n",
      "0.3333333333333333\n",
      " \n",
      "Subject8\n",
      "0.4166666666666667\n",
      " \n",
      "Subject9\n",
      "0.5\n",
      " \n",
      "Subject10\n",
      "0.6333333333333333\n",
      " \n",
      "Subject12\n",
      "0.4\n",
      " \n"
     ]
    }
   ],
   "source": [
    "allVowelAccuracyUnvoiced = []\n",
    "for subject in subjects:\n",
    "    print(subject)\n",
    "\n",
    "    DATA = np.load(\"Experiment1/Phoneme/Unvoiced\" + subject + \".npy\")\n",
    "   \n",
    "    mean = np.mean(DATA, axis = -1)\n",
    "    std = np.std(DATA, axis = -1)\n",
    "    unvoicedDATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "    phonemeMatrices = unvoicedDATA\n",
    "    labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberVowelPhoneme)]).reshape(numberVowelPhoneme * trialsPerPhoneme)\n",
    "\n",
    "    Indices =  {}\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        Indices[i] = []\n",
    "    for i in range(len(labelsByPhonemes)):\n",
    "        Indices[labelsByPhonemes[i]].append(i)\n",
    "\n",
    "    covariancesLabels = np.zeros((numberVowelPhoneme, trialsPerPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        for j in range(trialsPerPhoneme):\n",
    "            covariancesLabels[i, j] = 1/windowLength * (phonemeMatrices[230 + Indices[i][j]] @ phonemeMatrices[230 + Indices[i][j]].T)\n",
    "\n",
    "    trainFeatures = np.zeros((numberVowelPhoneme * 6, numberChannels, numberChannels))\n",
    "    trainLabels = np.zeros((numberVowelPhoneme * 6))\n",
    "    count = 0\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "        trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "        trainLabels[count:count + 6] = [i] * 6\n",
    "        count += 6\n",
    "\n",
    "    testFeatures = np.zeros((numberVowelPhoneme * 4, numberChannels, numberChannels))\n",
    "    testLabels = np.zeros((numberVowelPhoneme * 4))\n",
    "    count = 0\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "        testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "        testLabels[count:count + 4] = [i] * 4\n",
    "        count += 4\n",
    "\n",
    "    trainCentroid = np.zeros((numberVowelPhoneme, numberChannels, numberChannels))\n",
    "    for i in range(numberVowelPhoneme):\n",
    "        trainCentroid[i, :, :] = manifoldMean.mean(trainFeatures[i * 6: i * 6 + 6])\n",
    "\n",
    "    predictLabels = np.zeros((4 * numberVowelPhoneme))\n",
    "    for k in range(4 * numberVowelPhoneme):\n",
    "        distances = np.zeros((numberVowelPhoneme))\n",
    "        for m in range(numberVowelPhoneme):\n",
    "            distances[m] = geodesicDistance.distance(testFeatures[k], trainCentroid[m])\n",
    "        predictLabels[k] = np.argmin(distances)\n",
    "\n",
    "    correct = (predictLabels == testLabels)\n",
    "    print(np.mean(correct))\n",
    "    print(\" \")\n",
    "    allVowelAccuracyUnvoiced.append(np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4893939393939393\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(allVowelAccuracyUnvoiced))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emgSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
