{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subjects articulate 38 distinct phonemes that span the entire English language phonetic space in `silent' and `audible' manner. \n",
    "\n",
    "38 phonemes are (labels are given in brackets beside the phoneme)\n",
    "\n",
    "Bilabial consonants: Baa (0), Paa (1), Maa (2)\n",
    "Labiodental consonants: Faa (3), Vaa (4)\n",
    "Dental consonants: Thaa (5), Dhaa (6)\n",
    "Alvelor consonants: Taa (7), Daa (8), Naa (9), Saa (10), Zaa (11)\n",
    "Post vaelor consonants: Chaa (12), Shaa (13), Jhaa (14), Zhaa (15)\n",
    "Velar consonants: Kaa (!6), Gaa (17), NGaa (18)\n",
    "Approximant consonants: Yaa (19), Raa (20), Laa (21), Waa (22)\n",
    "Vowels:\n",
    "OY as in bOY (23), OW as in nOW (24),\n",
    "AO as in OUght (25), AA as in fAther (26),\n",
    "AE as in At (27), EH as in mEt (28),\n",
    "EY as in mAte (29), IY as in mEET (30),\n",
    "IH as in It (31), AH as in HUt (32),\n",
    "UW as in fOOD (33), ER as in hER (34),\n",
    "UH as in hOOD (35)\n",
    "\n",
    "DATA is given in a numpy array of dimensions (380, 22, 7500) - (38 phonemes each repeated 10 times, 22 channels, 7500 time samples).\n",
    "Raw data was filtered using 3rd order Butterworth bandpass filter between 80 and 1000 Hertz.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifoldRnn import spdNN\n",
    "from manifoldRnn import optimizers \n",
    "from manifoldRnn import trainTest\n",
    "from manifoldRnn import spdRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index].astype('float32'), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda:0\" \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberPhonemes = 38\n",
    "numberConsonantPhonemes = 23\n",
    "trialsPerPhoneme = 10\n",
    "numberTrials = numberPhonemes * trialsPerPhoneme\n",
    "numberChannels = 22\n",
    "windowLength = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectNumber = 1\n",
    "articulationManner = \"Voiced\"\n",
    "subject = \"Subject\" + str(subjectNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.load(\"Experiment1/Phoneme/\" + articulationManner + subject + \".npy\")\n",
    "   \n",
    "mean = np.mean(DATA, axis = -1)\n",
    "std = np.std(DATA, axis = -1)\n",
    "DATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "phonemeMatrices = DATA\n",
    "labelsByPhonemes = np.array([[i] * trialsPerPhoneme for i in range(numberConsonantPhonemes)]).reshape(numberConsonantPhonemes * trialsPerPhoneme)\n",
    "\n",
    "Indices =  {}\n",
    "for i in range(numberConsonantPhonemes):\n",
    "    Indices[i] = []\n",
    "for i in range(len(labelsByPhonemes)):\n",
    "    Indices[labelsByPhonemes[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicedMatrices = np.zeros((numberConsonantPhonemes * trialsPerPhoneme, 46, numberChannels, numberChannels))\n",
    "for j in range(numberConsonantPhonemes * trialsPerPhoneme):\n",
    "    for i in range(46):\n",
    "        where = i * 150 + 300\n",
    "        start = where - 300\n",
    "        End = where + 450\n",
    "        slicedMatrices[j, i] = 1/750 * phonemeMatrices[j, :, start:End] @ phonemeMatrices[j, :, start:End].T\n",
    "\n",
    "covariancesLabels = np.zeros((numberConsonantPhonemes, trialsPerPhoneme, 46, numberChannels, numberChannels))\n",
    "for i in range(numberConsonantPhonemes):\n",
    "    for j in range(trialsPerPhoneme):\n",
    "        covariancesLabels[i, j] = slicedMatrices[Indices[i][j]]\n",
    "\n",
    "trainFeatures = np.zeros((numberConsonantPhonemes * 6, 46, numberChannels, numberChannels))\n",
    "trainLabels = np.zeros((numberConsonantPhonemes * 6))\n",
    "count = 0\n",
    "for i in range(numberConsonantPhonemes):\n",
    "    trainFeatures[count:count + 3] = covariancesLabels[i, :3]\n",
    "    trainFeatures[count + 3:count + 6] = covariancesLabels[i, 5:8]\n",
    "    trainLabels[count:count + 6] = [i] * 6\n",
    "    count += 6\n",
    "\n",
    "testFeatures = np.zeros((numberConsonantPhonemes * 4, 46, numberChannels, numberChannels))\n",
    "testLabels = np.zeros((numberConsonantPhonemes * 4))\n",
    "count = 0\n",
    "for i in range(numberConsonantPhonemes):\n",
    "    testFeatures[count:count + 2] = covariancesLabels[i, 3:5]\n",
    "    testFeatures[count + 2:count + 4] = covariancesLabels[i, 8:10]\n",
    "    testLabels[count:count + 4] = [i] * 4\n",
    "    count += 4\n",
    "\n",
    "trainDataset = BaseDataset(trainFeatures, trainLabels)\n",
    "testDataset = BaseDataset(testFeatures, testLabels)\n",
    "trainDataloader = DataLoader(trainDataset, batch_size = 32, shuffle = True)\n",
    "testDataloader = DataLoader(testDataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145536\n"
     ]
    }
   ],
   "source": [
    "numberEpochs = 150\n",
    "\n",
    "model = spdRnn.spdRnnNet(numberConsonantPhonemes).to(device)\n",
    "numParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(numParams)\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "cnnOptimizer = optimizers.StiefelOptim(model.CNN.parameters(), lr = 0.05)\n",
    "rnnOptimizer = optim.Adam(model.RNN.parameters(), lr = 0.001, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/150, Training loss: 0.1150, Training accuracy: 4.35%, Test loss: 0.1020, Test accuracy: 7.61%\n",
      "Epoch: 2/150, Training loss: 0.1133, Training accuracy: 7.97%, Test loss: 0.1014, Test accuracy: 6.52%\n",
      "Epoch: 3/150, Training loss: 0.1121, Training accuracy: 4.35%, Test loss: 0.1007, Test accuracy: 6.52%\n",
      "Epoch: 4/150, Training loss: 0.1117, Training accuracy: 10.14%, Test loss: 0.1000, Test accuracy: 11.96%\n",
      "Epoch: 5/150, Training loss: 0.1103, Training accuracy: 21.01%, Test loss: 0.0982, Test accuracy: 17.39%\n",
      "Epoch: 6/150, Training loss: 0.1081, Training accuracy: 20.29%, Test loss: 0.0975, Test accuracy: 15.22%\n",
      "Epoch: 7/150, Training loss: 0.1051, Training accuracy: 15.94%, Test loss: 0.0962, Test accuracy: 9.78%\n",
      "Epoch: 8/150, Training loss: 0.1030, Training accuracy: 21.01%, Test loss: 0.0906, Test accuracy: 20.65%\n",
      "Epoch: 9/150, Training loss: 0.0987, Training accuracy: 30.43%, Test loss: 0.0875, Test accuracy: 25.00%\n",
      "Epoch: 10/150, Training loss: 0.0933, Training accuracy: 25.36%, Test loss: 0.0878, Test accuracy: 21.74%\n",
      "Epoch: 11/150, Training loss: 0.0894, Training accuracy: 26.81%, Test loss: 0.0861, Test accuracy: 17.39%\n",
      "Epoch: 12/150, Training loss: 0.0865, Training accuracy: 24.64%, Test loss: 0.0825, Test accuracy: 23.91%\n",
      "Epoch: 13/150, Training loss: 0.0868, Training accuracy: 26.09%, Test loss: 0.0793, Test accuracy: 29.35%\n",
      "Epoch: 14/150, Training loss: 0.0855, Training accuracy: 32.61%, Test loss: 0.0856, Test accuracy: 19.57%\n",
      "Epoch: 15/150, Training loss: 0.0823, Training accuracy: 29.71%, Test loss: 0.0787, Test accuracy: 32.61%\n",
      "Epoch: 16/150, Training loss: 0.0819, Training accuracy: 36.96%, Test loss: 0.0777, Test accuracy: 21.74%\n",
      "Epoch: 17/150, Training loss: 0.0806, Training accuracy: 38.41%, Test loss: 0.0781, Test accuracy: 19.57%\n",
      "Epoch: 18/150, Training loss: 0.0788, Training accuracy: 28.26%, Test loss: 0.0696, Test accuracy: 33.70%\n",
      "Epoch: 19/150, Training loss: 0.0752, Training accuracy: 32.61%, Test loss: 0.0699, Test accuracy: 29.35%\n",
      "Epoch: 20/150, Training loss: 0.0743, Training accuracy: 36.23%, Test loss: 0.0706, Test accuracy: 40.22%\n",
      "Epoch: 21/150, Training loss: 0.0721, Training accuracy: 40.58%, Test loss: 0.0654, Test accuracy: 34.78%\n",
      "Epoch: 22/150, Training loss: 0.0644, Training accuracy: 44.93%, Test loss: 0.0652, Test accuracy: 35.87%\n",
      "Epoch: 23/150, Training loss: 0.0623, Training accuracy: 40.58%, Test loss: 0.0708, Test accuracy: 27.17%\n",
      "Epoch: 24/150, Training loss: 0.0623, Training accuracy: 49.28%, Test loss: 0.0703, Test accuracy: 35.87%\n",
      "Epoch: 25/150, Training loss: 0.0624, Training accuracy: 49.28%, Test loss: 0.0656, Test accuracy: 30.43%\n",
      "Epoch: 26/150, Training loss: 0.0584, Training accuracy: 44.20%, Test loss: 0.0627, Test accuracy: 35.87%\n",
      "Epoch: 27/150, Training loss: 0.0537, Training accuracy: 52.17%, Test loss: 0.0586, Test accuracy: 44.57%\n",
      "Epoch: 28/150, Training loss: 0.0553, Training accuracy: 55.07%, Test loss: 0.0654, Test accuracy: 42.39%\n",
      "Epoch: 29/150, Training loss: 0.0597, Training accuracy: 44.20%, Test loss: 0.0627, Test accuracy: 40.22%\n",
      "Epoch: 30/150, Training loss: 0.0640, Training accuracy: 45.65%, Test loss: 0.0677, Test accuracy: 31.52%\n",
      "Epoch: 31/150, Training loss: 0.0595, Training accuracy: 49.28%, Test loss: 0.0678, Test accuracy: 32.61%\n",
      "Epoch: 32/150, Training loss: 0.0512, Training accuracy: 53.62%, Test loss: 0.0607, Test accuracy: 39.13%\n",
      "Epoch: 33/150, Training loss: 0.0529, Training accuracy: 52.90%, Test loss: 0.0624, Test accuracy: 48.91%\n",
      "Epoch: 34/150, Training loss: 0.0520, Training accuracy: 55.07%, Test loss: 0.0619, Test accuracy: 32.61%\n",
      "Epoch: 35/150, Training loss: 0.0486, Training accuracy: 54.35%, Test loss: 0.0524, Test accuracy: 45.65%\n",
      "Epoch: 36/150, Training loss: 0.0455, Training accuracy: 57.97%, Test loss: 0.0507, Test accuracy: 53.26%\n",
      "Epoch: 37/150, Training loss: 0.0411, Training accuracy: 66.67%, Test loss: 0.0516, Test accuracy: 48.91%\n",
      "Epoch: 38/150, Training loss: 0.0388, Training accuracy: 65.94%, Test loss: 0.0546, Test accuracy: 44.57%\n",
      "Epoch: 39/150, Training loss: 0.0376, Training accuracy: 65.22%, Test loss: 0.0526, Test accuracy: 46.74%\n",
      "Epoch: 40/150, Training loss: 0.0326, Training accuracy: 71.74%, Test loss: 0.0522, Test accuracy: 50.00%\n",
      "Epoch: 41/150, Training loss: 0.0348, Training accuracy: 68.84%, Test loss: 0.0511, Test accuracy: 54.35%\n",
      "Epoch: 42/150, Training loss: 0.0354, Training accuracy: 69.57%, Test loss: 0.0576, Test accuracy: 40.22%\n",
      "Epoch: 43/150, Training loss: 0.0418, Training accuracy: 58.70%, Test loss: 0.0486, Test accuracy: 55.43%\n",
      "Epoch: 44/150, Training loss: 0.0364, Training accuracy: 65.22%, Test loss: 0.0559, Test accuracy: 42.39%\n",
      "Epoch: 45/150, Training loss: 0.0378, Training accuracy: 60.14%, Test loss: 0.0510, Test accuracy: 43.48%\n",
      "Epoch: 46/150, Training loss: 0.0350, Training accuracy: 71.01%, Test loss: 0.0520, Test accuracy: 52.17%\n",
      "Epoch: 47/150, Training loss: 0.0352, Training accuracy: 65.22%, Test loss: 0.0501, Test accuracy: 47.83%\n",
      "Epoch: 48/150, Training loss: 0.0358, Training accuracy: 69.57%, Test loss: 0.0461, Test accuracy: 57.61%\n",
      "Epoch: 49/150, Training loss: 0.0285, Training accuracy: 75.36%, Test loss: 0.0540, Test accuracy: 51.09%\n",
      "Epoch: 50/150, Training loss: 0.0349, Training accuracy: 70.29%, Test loss: 0.0533, Test accuracy: 52.17%\n",
      "Epoch: 51/150, Training loss: 0.0390, Training accuracy: 56.52%, Test loss: 0.0569, Test accuracy: 38.04%\n",
      "Epoch: 52/150, Training loss: 0.0411, Training accuracy: 56.52%, Test loss: 0.0606, Test accuracy: 42.39%\n",
      "Epoch: 53/150, Training loss: 0.0411, Training accuracy: 58.70%, Test loss: 0.0506, Test accuracy: 51.09%\n",
      "Epoch: 54/150, Training loss: 0.0369, Training accuracy: 73.91%, Test loss: 0.0476, Test accuracy: 52.17%\n",
      "Epoch: 55/150, Training loss: 0.0371, Training accuracy: 72.46%, Test loss: 0.0535, Test accuracy: 47.83%\n",
      "Epoch: 56/150, Training loss: 0.0322, Training accuracy: 76.81%, Test loss: 0.0484, Test accuracy: 53.26%\n",
      "Epoch: 57/150, Training loss: 0.0359, Training accuracy: 65.94%, Test loss: 0.0538, Test accuracy: 53.26%\n",
      "Epoch: 58/150, Training loss: 0.0313, Training accuracy: 68.84%, Test loss: 0.0593, Test accuracy: 48.91%\n",
      "Epoch: 59/150, Training loss: 0.0341, Training accuracy: 69.57%, Test loss: 0.0501, Test accuracy: 55.43%\n",
      "Epoch: 60/150, Training loss: 0.0303, Training accuracy: 73.91%, Test loss: 0.0502, Test accuracy: 46.74%\n",
      "Epoch: 61/150, Training loss: 0.0295, Training accuracy: 76.09%, Test loss: 0.0514, Test accuracy: 56.52%\n",
      "Epoch: 62/150, Training loss: 0.0382, Training accuracy: 68.12%, Test loss: 0.0727, Test accuracy: 43.48%\n",
      "Epoch: 63/150, Training loss: 0.0321, Training accuracy: 71.01%, Test loss: 0.0572, Test accuracy: 53.26%\n",
      "Epoch: 64/150, Training loss: 0.0396, Training accuracy: 71.01%, Test loss: 0.0491, Test accuracy: 61.96%\n",
      "Epoch: 65/150, Training loss: 0.0392, Training accuracy: 71.01%, Test loss: 0.0515, Test accuracy: 47.83%\n",
      "Epoch: 66/150, Training loss: 0.0382, Training accuracy: 65.94%, Test loss: 0.0515, Test accuracy: 53.26%\n",
      "Epoch: 67/150, Training loss: 0.0446, Training accuracy: 63.77%, Test loss: 0.0618, Test accuracy: 43.48%\n",
      "Epoch: 68/150, Training loss: 0.0368, Training accuracy: 73.91%, Test loss: 0.0581, Test accuracy: 51.09%\n",
      "Epoch: 69/150, Training loss: 0.0266, Training accuracy: 76.09%, Test loss: 0.0497, Test accuracy: 55.43%\n",
      "Epoch: 70/150, Training loss: 0.0264, Training accuracy: 78.26%, Test loss: 0.0516, Test accuracy: 54.35%\n",
      "Epoch: 71/150, Training loss: 0.0257, Training accuracy: 80.43%, Test loss: 0.0551, Test accuracy: 57.61%\n",
      "Epoch: 72/150, Training loss: 0.0244, Training accuracy: 78.99%, Test loss: 0.0455, Test accuracy: 64.13%\n",
      "Epoch: 73/150, Training loss: 0.0199, Training accuracy: 83.33%, Test loss: 0.0404, Test accuracy: 59.78%\n",
      "Epoch: 74/150, Training loss: 0.0219, Training accuracy: 81.88%, Test loss: 0.0432, Test accuracy: 61.96%\n",
      "Epoch: 75/150, Training loss: 0.0193, Training accuracy: 83.33%, Test loss: 0.0409, Test accuracy: 64.13%\n",
      "Epoch: 76/150, Training loss: 0.0147, Training accuracy: 91.30%, Test loss: 0.0458, Test accuracy: 57.61%\n",
      "Epoch: 77/150, Training loss: 0.0140, Training accuracy: 91.30%, Test loss: 0.0456, Test accuracy: 58.70%\n",
      "Epoch: 78/150, Training loss: 0.0124, Training accuracy: 92.75%, Test loss: 0.0372, Test accuracy: 61.96%\n",
      "Epoch: 79/150, Training loss: 0.0119, Training accuracy: 94.93%, Test loss: 0.0380, Test accuracy: 64.13%\n",
      "Epoch: 80/150, Training loss: 0.0098, Training accuracy: 95.65%, Test loss: 0.0376, Test accuracy: 66.30%\n",
      "Epoch: 81/150, Training loss: 0.0088, Training accuracy: 95.65%, Test loss: 0.0460, Test accuracy: 60.87%\n",
      "Epoch: 82/150, Training loss: 0.0085, Training accuracy: 96.38%, Test loss: 0.0483, Test accuracy: 57.61%\n",
      "Epoch: 83/150, Training loss: 0.0091, Training accuracy: 94.93%, Test loss: 0.0466, Test accuracy: 56.52%\n",
      "Epoch: 84/150, Training loss: 0.0111, Training accuracy: 93.48%, Test loss: 0.0558, Test accuracy: 56.52%\n",
      "Epoch: 85/150, Training loss: 0.0146, Training accuracy: 91.30%, Test loss: 0.0457, Test accuracy: 63.04%\n",
      "Epoch: 86/150, Training loss: 0.0124, Training accuracy: 91.30%, Test loss: 0.0493, Test accuracy: 61.96%\n",
      "Epoch: 87/150, Training loss: 0.0131, Training accuracy: 91.30%, Test loss: 0.0647, Test accuracy: 52.17%\n",
      "Epoch: 88/150, Training loss: 0.0177, Training accuracy: 81.16%, Test loss: 0.0529, Test accuracy: 56.52%\n",
      "Epoch: 89/150, Training loss: 0.0146, Training accuracy: 86.96%, Test loss: 0.0395, Test accuracy: 67.39%\n",
      "Epoch: 90/150, Training loss: 0.0144, Training accuracy: 87.68%, Test loss: 0.0480, Test accuracy: 56.52%\n",
      "Epoch: 91/150, Training loss: 0.0132, Training accuracy: 87.68%, Test loss: 0.0425, Test accuracy: 63.04%\n",
      "Epoch: 92/150, Training loss: 0.0097, Training accuracy: 93.48%, Test loss: 0.0410, Test accuracy: 60.87%\n",
      "Epoch: 93/150, Training loss: 0.0067, Training accuracy: 97.83%, Test loss: 0.0403, Test accuracy: 65.22%\n",
      "Epoch: 94/150, Training loss: 0.0052, Training accuracy: 98.55%, Test loss: 0.0429, Test accuracy: 58.70%\n",
      "Epoch: 95/150, Training loss: 0.0050, Training accuracy: 97.83%, Test loss: 0.0438, Test accuracy: 64.13%\n",
      "Epoch: 96/150, Training loss: 0.0074, Training accuracy: 94.20%, Test loss: 0.0542, Test accuracy: 57.61%\n",
      "Epoch: 97/150, Training loss: 0.0096, Training accuracy: 94.20%, Test loss: 0.0539, Test accuracy: 56.52%\n",
      "Epoch: 98/150, Training loss: 0.0076, Training accuracy: 93.48%, Test loss: 0.0390, Test accuracy: 69.57%\n",
      "Epoch: 99/150, Training loss: 0.0058, Training accuracy: 97.10%, Test loss: 0.0440, Test accuracy: 61.96%\n",
      "Epoch: 100/150, Training loss: 0.0059, Training accuracy: 97.10%, Test loss: 0.0451, Test accuracy: 61.96%\n",
      "Epoch: 101/150, Training loss: 0.0054, Training accuracy: 96.38%, Test loss: 0.0416, Test accuracy: 69.57%\n",
      "Epoch: 102/150, Training loss: 0.0056, Training accuracy: 97.10%, Test loss: 0.0482, Test accuracy: 65.22%\n",
      "Epoch: 103/150, Training loss: 0.0065, Training accuracy: 95.65%, Test loss: 0.0604, Test accuracy: 60.87%\n",
      "Epoch: 104/150, Training loss: 0.0086, Training accuracy: 94.20%, Test loss: 0.0487, Test accuracy: 61.96%\n",
      "Epoch: 105/150, Training loss: 0.0100, Training accuracy: 92.03%, Test loss: 0.0603, Test accuracy: 56.52%\n",
      "Epoch: 106/150, Training loss: 0.0124, Training accuracy: 91.30%, Test loss: 0.0468, Test accuracy: 61.96%\n",
      "Epoch: 107/150, Training loss: 0.0106, Training accuracy: 91.30%, Test loss: 0.0451, Test accuracy: 57.61%\n",
      "Epoch: 108/150, Training loss: 0.0091, Training accuracy: 92.75%, Test loss: 0.0479, Test accuracy: 60.87%\n",
      "Epoch: 109/150, Training loss: 0.0060, Training accuracy: 96.38%, Test loss: 0.0561, Test accuracy: 56.52%\n",
      "Epoch: 110/150, Training loss: 0.0056, Training accuracy: 96.38%, Test loss: 0.0508, Test accuracy: 57.61%\n",
      "Epoch: 111/150, Training loss: 0.0055, Training accuracy: 96.38%, Test loss: 0.0371, Test accuracy: 67.39%\n",
      "Epoch: 112/150, Training loss: 0.0043, Training accuracy: 97.83%, Test loss: 0.0422, Test accuracy: 67.39%\n",
      "Epoch: 113/150, Training loss: 0.0032, Training accuracy: 99.28%, Test loss: 0.0427, Test accuracy: 69.57%\n",
      "Epoch: 114/150, Training loss: 0.0021, Training accuracy: 100.00%, Test loss: 0.0452, Test accuracy: 69.57%\n",
      "Epoch: 115/150, Training loss: 0.0019, Training accuracy: 99.28%, Test loss: 0.0461, Test accuracy: 67.39%\n",
      "Epoch: 116/150, Training loss: 0.0025, Training accuracy: 100.00%, Test loss: 0.0469, Test accuracy: 68.48%\n",
      "Epoch: 117/150, Training loss: 0.0017, Training accuracy: 100.00%, Test loss: 0.0468, Test accuracy: 68.48%\n",
      "Epoch: 118/150, Training loss: 0.0021, Training accuracy: 100.00%, Test loss: 0.0457, Test accuracy: 68.48%\n",
      "Epoch: 119/150, Training loss: 0.0017, Training accuracy: 100.00%, Test loss: 0.0477, Test accuracy: 68.48%\n",
      "Epoch: 120/150, Training loss: 0.0013, Training accuracy: 100.00%, Test loss: 0.0440, Test accuracy: 69.57%\n",
      "Epoch: 121/150, Training loss: 0.0014, Training accuracy: 100.00%, Test loss: 0.0465, Test accuracy: 69.57%\n",
      "Epoch: 122/150, Training loss: 0.0010, Training accuracy: 100.00%, Test loss: 0.0482, Test accuracy: 69.57%\n",
      "Epoch: 123/150, Training loss: 0.0011, Training accuracy: 100.00%, Test loss: 0.0507, Test accuracy: 70.65%\n",
      "Epoch: 124/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0526, Test accuracy: 63.04%\n",
      "Epoch: 125/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0507, Test accuracy: 67.39%\n",
      "Epoch: 126/150, Training loss: 0.0008, Training accuracy: 100.00%, Test loss: 0.0518, Test accuracy: 68.48%\n",
      "Epoch: 127/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0542, Test accuracy: 64.13%\n",
      "Epoch: 128/150, Training loss: 0.0008, Training accuracy: 100.00%, Test loss: 0.0562, Test accuracy: 65.22%\n",
      "Epoch: 129/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0508, Test accuracy: 64.13%\n",
      "Epoch: 130/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0533, Test accuracy: 67.39%\n",
      "Epoch: 131/150, Training loss: 0.0009, Training accuracy: 100.00%, Test loss: 0.0584, Test accuracy: 64.13%\n",
      "Epoch: 132/150, Training loss: 0.0007, Training accuracy: 100.00%, Test loss: 0.0537, Test accuracy: 65.22%\n",
      "Epoch: 133/150, Training loss: 0.0006, Training accuracy: 100.00%, Test loss: 0.0553, Test accuracy: 63.04%\n",
      "Epoch: 134/150, Training loss: 0.0006, Training accuracy: 100.00%, Test loss: 0.0570, Test accuracy: 64.13%\n",
      "Epoch: 135/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0557, Test accuracy: 67.39%\n",
      "Epoch: 136/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0541, Test accuracy: 64.13%\n",
      "Epoch: 137/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0559, Test accuracy: 67.39%\n",
      "Epoch: 138/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0547, Test accuracy: 67.39%\n",
      "Epoch: 139/150, Training loss: 0.0005, Training accuracy: 100.00%, Test loss: 0.0531, Test accuracy: 67.39%\n",
      "Epoch: 140/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0544, Test accuracy: 66.30%\n",
      "Epoch: 141/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0579, Test accuracy: 64.13%\n",
      "Epoch: 142/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0575, Test accuracy: 59.78%\n",
      "Epoch: 143/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0577, Test accuracy: 63.04%\n",
      "Epoch: 144/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0582, Test accuracy: 66.30%\n",
      "Epoch: 145/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0578, Test accuracy: 67.39%\n",
      "Epoch: 146/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0561, Test accuracy: 64.13%\n",
      "Epoch: 147/150, Training loss: 0.0003, Training accuracy: 100.00%, Test loss: 0.0574, Test accuracy: 66.30%\n",
      "Epoch: 148/150, Training loss: 0.0004, Training accuracy: 100.00%, Test loss: 0.0577, Test accuracy: 66.30%\n",
      "Epoch: 149/150, Training loss: 0.0009, Training accuracy: 99.28%, Test loss: 0.0639, Test accuracy: 63.04%\n",
      "Epoch: 150/150, Training loss: 0.0040, Training accuracy: 96.38%, Test loss: 0.0603, Test accuracy: 64.13%\n",
      "70.65217391304348\n"
     ]
    }
   ],
   "source": [
    "maxValue = 0\n",
    "for epoch in range(numberEpochs):\n",
    "    trainLoss, trainAccuracy = trainTest.trainOperation(model, device, trainDataloader, cnnOptimizer, rnnOptimizer, lossFunction)\n",
    "    testLoss, testAccuracy = trainTest.testOperation(model, device, testDataloader, lossFunction)\n",
    "    if maxValue < testAccuracy:\n",
    "        maxValue = testAccuracy\n",
    "    print(f'Epoch: {epoch + 1}/{numberEpochs}, Training loss: {trainLoss:.4f}, Training accuracy: {trainAccuracy:.2f}%, Test loss: {testLoss:.4f}, Test accuracy: {testAccuracy:.2f}%')\n",
    "print(maxValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.65217391304348\n"
     ]
    }
   ],
   "source": [
    "print(maxValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emgSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
